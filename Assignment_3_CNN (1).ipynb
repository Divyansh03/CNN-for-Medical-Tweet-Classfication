{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data comprises tweets pertaining to common causes of cancer. The objective is to classify the tweets as medically relevant or not.  The dataset is skewed with positive class or 'yes' being 6 times less frequent than the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 1298)\n",
      "7724\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "# these are the modules you are allowed to work with. \n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import sys, os\n",
    "import random\n",
    "\n",
    "'''\n",
    "First job is to clean and preprocess the social media text. (5)\n",
    "\n",
    "1) Replace URLs and mentions (i.e strings which are preceeded with @)\n",
    "2) Segment #hastags \n",
    "3) Remove emoticons and other unicode characters\n",
    "'''\n",
    "\n",
    "def preprocess_tweet(input_text):\n",
    "    '''\n",
    "    Input: The input string read directly from the file\n",
    "    \n",
    "    Output: Pre-processed tweet text\n",
    "    '''\n",
    "    s= re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", input_text) #removing hashtags and mentions\n",
    "    s=re.sub(r'[^\\x00-\\x7f]',r'', s)  #removing emoticons and unicode characters\n",
    "    r=[]\n",
    "    for i in s.split(): #segmenting hashtags\n",
    "        if i.startswith(\"#\"):\n",
    "            i=i[1:]\n",
    "            splitted = re.sub('(?!^)([A-Z][a-z]+)', r' \\1', i).split()\n",
    "            r.extend(splitted)\n",
    "        else:\n",
    "            r.append(i)\n",
    "    cleaned_text = ' '.join(r) \n",
    "    cleaned_text = re.sub(r'[^\\w\\s]','',cleaned_text) # removing punctuation such as . , ? ! which unnecessarily increase vocab size\n",
    "    cleaned_text=cleaned_text.lower() # converting words to lower case\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# read the input file and create the set of positive examples and negative examples. \n",
    "\n",
    "file=open('cancer_data.tsv')\n",
    "pos_data=[]\n",
    "neg_data=[]\n",
    "\n",
    "for line in file:\n",
    "    line=line.strip().split('\\t')\n",
    "    text2= preprocess_tweet(line[0]).strip().split()\n",
    "    if line[1]=='yes':\n",
    "        pos_data.append(text2)\n",
    "    if line[1]=='no':\n",
    "        neg_data.append(text2)\n",
    "\n",
    "print(len(pos_data), len(neg_data))     \n",
    "\n",
    "sentences= list(pos_data)\n",
    "sentences.extend(neg_data)\n",
    "#print (sentences)\n",
    "pos_labels= [1 for _ in pos_data]\n",
    "neg_labels= [0 for _ in neg_data]\n",
    "y=list(pos_labels)\n",
    "y.extend(neg_labels)\n",
    "y=np.array(y)\n",
    "\n",
    "'''\n",
    "After this you will obtain the following :\n",
    "\n",
    "1) sentences =  List of sentences having the positive and negative examples with all the positive examples first\n",
    "2) y = List of labels with the positive labels first.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Before running the CNN there are a few things one needs to take care of: (5)\n",
    "\n",
    "1) Pad the sentences so that all of them are of the same length\n",
    "2) Build a vocabulary comprising all unique words that occur in the corpus\n",
    "3) Convert each sentence into a corresponding vector by replacing each word in the sentence with the index in the vocabulary. \n",
    "\n",
    "Example :\n",
    "S1 = a b a c\n",
    "S2 = d c a \n",
    "\n",
    "Step 1:  S1= a b a c, \n",
    "         S2 =d c a </s> \n",
    "         (Both sentences are of equal length). \n",
    "\n",
    "Step 2:  voc={a:1, b:2, c:3, d:4, </s>: 5}\n",
    "\n",
    "Step 3:  S1= [1,2,1,3]\n",
    "         S2= [4,3,1,5]\n",
    "\n",
    "'''\n",
    "def pad_sentences(sentences, padding_word=\"\"): #function for padding sentences\n",
    "    \"\"\"\n",
    "    Pads all sentences to be the length of the longest sentence.\n",
    "    Returns padded sentences.\n",
    "    \"\"\"\n",
    "    sequence_length = max(len(x) for x in sentences)\n",
    "    padded_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        num_padding = sequence_length - len(sentence)\n",
    "        new_sentence = sentence + [padding_word] * num_padding\n",
    "        padded_sentences.append(new_sentence)\n",
    "        \n",
    "    return padded_sentences\n",
    "\n",
    "\n",
    "def build_vocab(sentences): #function for building vocabulary\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Builds a vocabulary mapping from token to index based on the sentences.\n",
    "    Returns vocabulary mapping and inverse vocabulary mapping.\n",
    "    \"\"\"\n",
    "    d={}\n",
    "    i=0\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in d:\n",
    "                d[word]=i\n",
    "                i=i+1\n",
    "    return d,i\n",
    "\n",
    "    \n",
    "            \n",
    "def create_word_vectors(sentences):  #function for creating the word vectors\n",
    "    '''\n",
    "    Input: List of sentences\n",
    "    Output: List of word vectors corresponding to each sentence, vocabulary\n",
    "    '''\n",
    "    sentences_padded = pad_sentences(sentences)\n",
    "    #print (len(sentences_padded[3]))\n",
    "    vocabulary,vocab_size = build_vocab(sentences_padded)\n",
    "    word_vectors= np.array([\n",
    "            [vocabulary[word] for word in sentence]\n",
    "            for sentence in sentences_padded])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return word_vectors, vocabulary, vocab_size\n",
    "\n",
    "\n",
    "x, vocabulary, vocab_size = create_word_vectors(sentences)\n",
    "sentence_size=len(x[0])\n",
    "print (vocab_size)\n",
    "print (sentence_size)\n",
    "\n",
    "\n",
    "\n",
    "def create_shuffle(x,y):\n",
    "    '''\n",
    "    Create an equal distribution of the positive and negative examples. \n",
    "    Please do not change this particular shuffling method.\n",
    "    '''\n",
    "    pos_len= len(pos_data)\n",
    "    neg_len= len(neg_data)\n",
    "    pos_len_train= int(0.8*pos_len)\n",
    "    neg_len_train= int(0.8*neg_len)\n",
    "    train_data= [(x[i],y[i]) for i in range(0, pos_len_train)]\n",
    "    train_data.extend([(x[i],y[i]) for i in range(pos_len, pos_len+ neg_len_train )])\n",
    "    test_data=[(x[i],y[i]) for i in range(pos_len_train, pos_len)]\n",
    "    test_data.extend([(x[i],y[i]) for i in range(pos_len+ neg_len_train, len(x) )])\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "    x_train=[i[0] for i in train_data]\n",
    "    y_train=[i[1] for i in train_data]\n",
    "    random.shuffle(test_data)\n",
    "    x_test=[i[0] for i in test_data]\n",
    "    y_test=[i[1] for i in test_data]\n",
    "    \n",
    "    x_train=np.array(x_train)\n",
    "    y_train=np.array(y_train)\n",
    "    x_test= np.array(x_test)\n",
    "    y_test= np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test= create_shuffle(x,y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('batch size', 20)\n",
      "('embedding dimensions', 200)\n",
      "('convolution filters', [2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We now define the neural architecture of the CNN. The architecture is defined as : (10)\n",
    "\n",
    "1) Embedding layer that converts the vector representation of the sentence from a one-hot encoding to a fixed sized word embedding\n",
    "   (mx.sym.Embedding)\n",
    "   \n",
    "2) Convolution + activation + max pooling layer \n",
    "   (mx.sym.Convolution+ mx.sym.Activation+ mx.sym.Pooling)\n",
    "   This procedure is to be followed for different sizes of filters (the filters corresponding to size 2 looks at the bigram distribution, 3 looks at trigram etc. \n",
    "\n",
    "3) Concat all the filters together (mx.sym.Concat)\n",
    "\n",
    "4) Pass the results through a fully Connected layer of size 2 and then run softmax on it. \n",
    "   (mx.sym.FullyConnected, mx.sym.SoftmaxOutput)\n",
    "   \n",
    "\n",
    "We then initialize the intermediate layers of appropriate size and train the model using back prop. (10)\n",
    "(Look up the mxnet tutorial if you have any doubt)\n",
    "\n",
    "Run the classifier and for each epoch with a specified batch size observe the accuracy on the training set and test set (5)\n",
    "\n",
    "\n",
    "Default parameters:\n",
    "\n",
    "1) No of epochs = 10\n",
    "2) Batch size = 20\n",
    "3) Size of word embeddings = 200\n",
    "4) Size of filters =[2,3,4,5]\n",
    "5) Filter embedding= 100\n",
    "6) Optimizer = rmsprop\n",
    "7) learning rate = 0.005\n",
    "\n",
    "'''\n",
    "batch_size = 20\n",
    "print('batch size', batch_size)\n",
    "\n",
    "input_x = mx.sym.Variable('data') # placeholder for input data\n",
    "input_y = mx.sym.Variable('softmax_label') # placeholder for output label\n",
    "\n",
    "\n",
    "'''\n",
    "Define the first network layer (embedding)\n",
    "'''\n",
    "\n",
    "# create embedding layer to learn representation of words in a lower dimensional subspace\n",
    "num_embed = 200 # dimensions to embed words into\n",
    "print('embedding dimensions', num_embed)\n",
    "\n",
    "embed_layer = mx.sym.Embedding(data=input_x, input_dim=vocab_size, output_dim=num_embed, name='vocab_embed')\n",
    "\n",
    "# reshape embedded data for next layer\n",
    "conv_input = mx.sym.Reshape(data=embed_layer, shape=(batch_size, 1, sentence_size, num_embed))\n",
    "\n",
    "filter_list=[2, 3, 4, 5] # the size of filters to use\n",
    "print('convolution filters', filter_list)\n",
    "\n",
    "num_filter=100\n",
    "pooled_outputs = []\n",
    "for filter_size in filter_list:\n",
    "    convi = mx.sym.Convolution(data=conv_input, kernel=(filter_size, num_embed), num_filter=num_filter)\n",
    "    relui = mx.sym.Activation(data=convi, act_type='relu')\n",
    "    pooli = mx.sym.Pooling(data=relui, pool_type='max', kernel=(sentence_size - filter_size + 1, 1), stride=(1, 1))\n",
    "    pooled_outputs.append(pooli)\n",
    "\n",
    "# combine all pooled outputs\n",
    "total_filters = num_filter * len(filter_list)\n",
    "concat = mx.sym.Concat(*pooled_outputs, dim=1)\n",
    "\n",
    "# reshape for next layer\n",
    "h_pool = mx.sym.Reshape(data=concat, shape=(batch_size, total_filters))\n",
    "\n",
    "num_label = 2\n",
    "\n",
    "cls_weight = mx.sym.Variable('cls_weight')\n",
    "cls_bias = mx.sym.Variable('cls_bias')\n",
    "\n",
    "fc = mx.sym.FullyConnected(data=h_pool, weight=cls_weight, bias=cls_bias, num_hidden=num_label)\n",
    "\n",
    "# softmax output\n",
    "sm = mx.sym.SoftmaxOutput(data=fc, label=input_y, name='softmax')\n",
    "\n",
    "# set CNN pointer to the \"back\" of the network\n",
    "cnn = sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Define the structure of our CNN Model (as a named tuple)\n",
    "CNNModel = namedtuple(\"CNNModel\", ['cnn_exec', 'symbol', 'data', 'label', 'param_blocks'])\n",
    "\n",
    "# Define what device to train/test on, use GPU if available\n",
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
    "\n",
    "arg_names = cnn.list_arguments()\n",
    "\n",
    "input_shapes = {}\n",
    "input_shapes['data'] = (batch_size, sentence_size)\n",
    "\n",
    "arg_shape, out_shape, aux_shape = cnn.infer_shape(**input_shapes)\n",
    "arg_arrays = [mx.nd.zeros(s, ctx) for s in arg_shape]\n",
    "args_grad = {}\n",
    "for shape, name in zip(arg_shape, arg_names):\n",
    "    if name in ['softmax_label', 'data']: # input, output\n",
    "        continue\n",
    "    args_grad[name] = mx.nd.zeros(shape, ctx)\n",
    "\n",
    "cnn_exec = cnn.bind(ctx=ctx, args=arg_arrays, args_grad=args_grad, grad_req='add')\n",
    "\n",
    "param_blocks = []\n",
    "arg_dict = dict(zip(arg_names, cnn_exec.arg_arrays))\n",
    "initializer = mx.initializer.Uniform(0.1)\n",
    "for i, name in enumerate(arg_names):\n",
    "    if name in ['softmax_label', 'data']: # input, output\n",
    "        continue\n",
    "    initializer(mx.init.InitDesc(name), arg_dict[name])\n",
    "\n",
    "    param_blocks.append( (i, arg_dict[name], args_grad[name], name) )\n",
    "\n",
    "data = cnn_exec.arg_dict['data']\n",
    "label = cnn_exec.arg_dict['softmax_label']\n",
    "\n",
    "cnn_model= CNNModel(cnn_exec=cnn_exec, symbol=cnn, data=data, label=label, param_blocks=param_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('optimizer', 'rmsprop')\n",
      "('maximum gradient', 5.0)\n",
      "('learning rate (step size)', 0.005)\n",
      "('epochs to train for', 10)\n",
      "Iter [0] Train: Time: 13.910s, Training Accuracy: 99.917                 --- Test Accuracy thus far: 90.667\n",
      "Iter [1] Train: Time: 13.728s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.333\n",
      "Iter [2] Train: Time: 13.562s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.333\n",
      "Iter [3] Train: Time: 13.617s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.333\n",
      "Iter [4] Train: Time: 13.618s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.000\n",
      "Iter [5] Train: Time: 13.623s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.000\n",
      "Iter [6] Train: Time: 13.565s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.000\n",
      "Iter [7] Train: Time: 13.835s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 90.667\n",
      "Iter [8] Train: Time: 15.003s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 89.667\n",
      "Saved checkpoint to ./cnn-0009.params\n",
      "Iter [9] Train: Time: 14.849s, Training Accuracy: 99.833                 --- Test Accuracy thus far: 89.667\n"
     ]
    }
   ],
   "source": [
    "optimizer = 'rmsprop'\n",
    "max_grad_norm = 5.0\n",
    "learning_rate = 0.005\n",
    "epoch = 10\n",
    "\n",
    "print('optimizer', optimizer)\n",
    "print('maximum gradient', max_grad_norm)\n",
    "print('learning rate (step size)', learning_rate)\n",
    "print('epochs to train for', epoch)\n",
    "\n",
    "# create optimizer\n",
    "opt = mx.optimizer.create(optimizer)\n",
    "opt.lr = learning_rate\n",
    "\n",
    "updater = mx.optimizer.get_updater(opt)\n",
    "\n",
    "# For each training epoch\n",
    "for iteration in range(epoch):\n",
    "    tic = time.time()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "\n",
    "    # Over each batch of training data\n",
    "    for begin in range(0, x_train.shape[0], batch_size):\n",
    "        batchX = x_train[begin:begin+batch_size]\n",
    "        batchY = y_train[begin:begin+batch_size]\n",
    "        if batchX.shape[0] != batch_size:\n",
    "            continue\n",
    "\n",
    "        cnn_model.data[:] = batchX\n",
    "        cnn_model.label[:] = batchY\n",
    "\n",
    "        # forward\n",
    "        cnn_model.cnn_exec.forward(is_train=True)\n",
    "\n",
    "        # backward\n",
    "        cnn_model.cnn_exec.backward()\n",
    "\n",
    "        # eval on training data\n",
    "        num_correct += sum(batchY == np.argmax(cnn_model.cnn_exec.outputs[0].asnumpy(), axis=1))\n",
    "        num_total += len(batchY)\n",
    "\n",
    "        # update weights\n",
    "        norm = 0\n",
    "        for idx, weight, grad, name in cnn_model.param_blocks:\n",
    "            grad /= batch_size\n",
    "            l2_norm = mx.nd.norm(grad).asscalar()\n",
    "            norm += l2_norm * l2_norm\n",
    "\n",
    "        norm = math.sqrt(norm)\n",
    "        for idx, weight, grad, name in cnn_model.param_blocks:\n",
    "            if norm > max_grad_norm:\n",
    "                grad *= (max_grad_norm / norm)\n",
    "\n",
    "            updater(idx, grad, weight)\n",
    "\n",
    "            # reset gradient to zero\n",
    "            grad[:] = 0.0\n",
    "\n",
    "    # Decay learning rate for this epoch to ensure we are not \"overshooting\" optima\n",
    "    if iteration % 50 == 0 and iteration > 0:\n",
    "        opt.lr *= 0.5\n",
    "        print('reset learning rate to %g' % opt.lr)\n",
    "\n",
    "    # End of training loop for this epoch\n",
    "    toc = time.time()\n",
    "    train_time = toc - tic\n",
    "    train_acc = num_correct * 100 / float(num_total)\n",
    "\n",
    "    # Saving checkpoint to disk\n",
    "    if (iteration + 1) % 10 == 0:\n",
    "        prefix = 'cnn'\n",
    "        cnn_model.symbol.save('./%s-symbol.json' % prefix)\n",
    "        save_dict = {('arg:%s' % k) : v  for k, v in cnn_model.cnn_exec.arg_dict.items()}\n",
    "        save_dict.update({('aux:%s' % k) : v for k, v in cnn_model.cnn_exec.aux_dict.items()})\n",
    "        param_name = './%s-%04d.params' % (prefix, iteration)\n",
    "        mx.nd.save(param_name, save_dict)\n",
    "        print('Saved checkpoint to %s' % param_name)\n",
    "\n",
    "\n",
    "    # Evaluate model after this epoch on dev (test) set\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "\n",
    "    # For each test batch\n",
    "    for begin in range(0, x_test.shape[0], batch_size):\n",
    "        batchX = x_test[begin:begin+batch_size]\n",
    "        batchY = y_test[begin:begin+batch_size]\n",
    "\n",
    "        if batchX.shape[0] != batch_size:\n",
    "            continue\n",
    "\n",
    "        cnn_model.data[:] = batchX\n",
    "        cnn_model.cnn_exec.forward(is_train=False)\n",
    "\n",
    "        num_correct += sum(batchY == np.argmax(cnn_model.cnn_exec.outputs[0].asnumpy(), axis=1))\n",
    "        num_total += len(batchY)\n",
    "        \n",
    "       \n",
    "\n",
    "    dev_acc = num_correct * 100 / float(num_total)\n",
    "    print('Iter [%d] Train: Time: %.3fs, Training Accuracy: %.3f \\\n",
    "                --- Test Accuracy thus far: %.3f' % (iteration, train_time, train_acc, dev_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSo far, the assignment has been posed in a manner so that you can refer to directly the mxnet tutorial on the same problem. \\n\\nThe final 15 marks is meant to carry out experimentations of your own and observe how the results change by experimentation. \\n\\n1) Would the results improve if instead of using the word embeddings that is based solely on frequency, if you have been able to incorporate sub-word information\\n   (In short run fasttext on the corpus and use the word embeddings generated by fastetxt). (8)\\n   \\n2) Accuracy might not be the best way to measure the performance of a skewed dataset. What other metrics would you use ? Why? \\n   Experiment with different hyper-paramters to show the performance in terms of metric? \\n   You can assume that we want to identify all the medically relevant tweets (i.e. tweets with 'yes' class more). (7)\\n    \\n\\nDelivearbles:\\n\\nThe ipython notebook with the results to each part of the question. \\n\\n\\nP.S: This assignment is part of a research question I am working on my free time. So if you have any insights, I'd love to hear them. \\nHappy coding \\n\\nRitam Dutt\\n14CS30041\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "So far, the assignment has been posed in a manner so that you can refer to directly the mxnet tutorial on the same problem. \n",
    "\n",
    "The final 15 marks is meant to carry out experimentations of your own and observe how the results change by experimentation. \n",
    "\n",
    "1) Would the results improve if instead of using the word embeddings that is based solely on frequency, if you have been able to incorporate sub-word information\n",
    "   (In short run fasttext on the corpus and use the word embeddings generated by fastetxt). (8)\n",
    "   \n",
    "2) Accuracy might not be the best way to measure the performance of a skewed dataset. What other metrics would you use ? Why? \n",
    "   Experiment with different hyper-paramters to show the performance in terms of metric? \n",
    "   You can assume that we want to identify all the medically relevant tweets (i.e. tweets with 'yes' class more). (7)\n",
    "    \n",
    "\n",
    "Deliverables:\n",
    "\n",
    "The ipython notebook with the results to each part of the question. \n",
    "\n",
    "\n",
    "P.S: This assignment is part of a research question I am working on my free time. So if you have any insights, I'd love to hear them. \n",
    "Happy coding \n",
    "\n",
    "Ritam Dutt\n",
    "14CS30041\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As part of my experiment I have used the gluonnlp implementation of fastText\n",
    "# Tutorial linked here-https://gluon-nlp.mxnet.io/examples/word_embedding/word_embedding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59581\n"
     ]
    }
   ],
   "source": [
    "s=sentences[0]  #creating vocabulary for fastText implementation\n",
    "for i in range(1,len(sentences)):\n",
    "    s=s+sentences[i]\n",
    "print (len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp   #creating fastText embedding using our vocabulary\n",
    "counter = nlp.data.count_tokens(s)\n",
    "my_vocab = nlp.Vocab(counter)\n",
    "fasttext = nlp.embedding.create('fasttext', source='wiki.simple')\n",
    "my_vocab.set_embedding(fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sen=pad_sentences(sentences)  #creating the word vectors\n",
    "g=np.array([my_vocab[p_sen[0]]])\n",
    "for i in range(1,len(p_sen)):\n",
    "    l=np.array([my_vocab[p_sen[i]]])\n",
    "    g=np.append(g,l,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(g, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from mxnet import gluon, autograd, metric\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data import Dataset, DataLoader\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "save_path = 'checkpoints'  # model save path\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "model_file = os.path.join(save_path, 'mr_cnn_mxnet.params')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu()\"\"\"\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "\n",
    "class TCNNConfig(object):\n",
    "    \"\"\"\n",
    "    CNN parameters\n",
    "    \"\"\"\n",
    "    embedding_dim = 300  # embedding vector size\n",
    "    seq_length = 50  # maximum length of sequence\n",
    "    vocab_size = 7727  # most common words\n",
    "\n",
    "    num_filters = 100  # number of the convolution filters (feature maps)\n",
    "    kernel_sizes = [2, 3, 4, 5]  # three kinds of kernels (windows)\n",
    "\n",
    "    dropout_prob = 0.6  # dropout rate\n",
    "    learning_rate = 1e-3  # learning rate\n",
    "    batch_size = 20 # batch size for training\n",
    "    num_epochs = 10 # total number of epochs\n",
    "\n",
    "    num_classes = 2  # number of classes\n",
    "\n",
    "    dev_split = 0.2 # percentage of dev data\n",
    "\n",
    "\n",
    "class Conv_Max_Pooling(nn.Block):\n",
    "    \"\"\"\n",
    "    Integration of Conv1D and GlobalMaxPool1D layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, kernel_size, **kwargs):\n",
    "        super(Conv_Max_Pooling, self).__init__(**kwargs)\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.conv = nn.Conv1D(channels, kernel_size)\n",
    "            self.pooling = nn.GlobalMaxPool1D()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pooling(self.conv(x))\n",
    "        return nd.relu(output).flatten()\n",
    "\n",
    "\n",
    "class TextCNN(nn.Block):\n",
    "    \"\"\"\n",
    "    CNN text classification model, based on the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "\n",
    "        V = config.vocab_size\n",
    "        E = config.embedding_dim\n",
    "        Nf = config.num_filters\n",
    "        Ks = config.kernel_sizes\n",
    "        C = config.num_classes\n",
    "        Dr = config.dropout_prob\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.embedding = nn.Embedding(V, E)  # embedding layer\n",
    "\n",
    "            # three different convolutional layers\n",
    "            self.conv1 = Conv_Max_Pooling(Nf, Ks[0])\n",
    "            self.conv2 = Conv_Max_Pooling(Nf, Ks[1])\n",
    "            self.conv3 = Conv_Max_Pooling(Nf, Ks[2])\n",
    "            self.dropout = nn.Dropout(Dr)  # a dropout layer\n",
    "            self.fc1 = nn.Dense(C)  # a dense layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).transpose((0, 2, 1))  # Conv1D takes in NCW as input\n",
    "        o1, o2, o3 = self.conv1(x), self.conv2(x), self.conv3(x)\n",
    "        outputs = self.fc1(self.dropout(nd.concat(o1, o2, o3)))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"\n",
    "    Return the time used since start_time.\n",
    "    \"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    return timedelta(seconds=int(round(time_dif)))\n",
    "\n",
    "\n",
    "class MRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An implementation of the Abstracted gluon.data.Dataset, used for loading data in batch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        super(MRDataset, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index].astype(np.float32), self.y[index].astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "def evaluate(data_loader, data_len, model, loss, ctx):\n",
    "    \"\"\"\n",
    "    Evaluation, return accuracy and loss\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    acc = metric.Accuracy()\n",
    "\n",
    "    for data, label in data_loader:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "\n",
    "        with autograd.record(train_mode=False):  # set the training_mode to False\n",
    "            output = model(data)\n",
    "            losses = loss(output, label)\n",
    "\n",
    "        total_loss += nd.sum(losses).asscalar()\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1], total_loss / data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lossy):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model with training and test data.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    start_time = time.time()\n",
    "    config = TCNNConfig()\n",
    "    \n",
    "    config.vocab_size = 7727\n",
    "\n",
    "    print(\"Configuring CNN model...\")\n",
    "    ctx = try_gpu()\n",
    "    model = TextCNN(config)\n",
    "    model.collect_params().initialize(ctx=ctx)\n",
    "    model.embedding.weight.set_data(my_vocab.embedding.idx_to_vec) #assigning weights to the embedding layer as generated by fastText\n",
    "    print(\"Initializing weights on\", ctx)\n",
    "    print(model)\n",
    "\n",
    "    # optimizer and loss function\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'adagrad', {'learning_rate': config.learning_rate})\n",
    "\n",
    "    batch_size = config.batch_size\n",
    "    train_loader = DataLoader(MRDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(MRDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(\"Training and evaluating...\")\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(config.num_epochs):\n",
    "        for data, label in train_loader:\n",
    "            data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "\n",
    "            with autograd.record(train_mode=True):  # set the model in training mode\n",
    "                output = model(data)\n",
    "                losses = loss(output, label)\n",
    "\n",
    "            # backward propagation and update parameters\n",
    "            losses.backward()\n",
    "            trainer.step(len(data))\n",
    "\n",
    "        # evaluate on both training and test dataset\n",
    "        train_acc, train_loss = evaluate(train_loader, x_train.shape[0], model, loss, ctx)\n",
    "        test_acc, test_loss = evaluate(test_loader, x_test.shape[0], model, loss, ctx)\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            # store the best result\n",
    "            best_acc = test_acc\n",
    "            improved_str = '*'\n",
    "            model.save_params(model_file)\n",
    "        else:\n",
    "            improved_str = ''\n",
    "\n",
    "        time_dif = get_time_dif(start_time)\n",
    "        msg = \"Epoch {0:3}, Train_loss: {1:>7.2}, Train_acc {2:>6.2%}, \" \\\n",
    "              + \"Test_loss: {3:>6.2}, Test_acc {4:>6.2%}, Time: {5} {6}\"\n",
    "        print(msg.format(epoch + 1, train_loss, train_acc, test_loss, test_acc, time_dif, improved_str))\n",
    "        lossy.append(train_loss)\n",
    "\n",
    "    test(model, test_loader, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, ctx):\n",
    "    \"\"\"\n",
    "    Test the model on test dataset.\n",
    "    \"\"\"\n",
    "    print(\"Testing...\")\n",
    "    start_time = time.time()\n",
    "    model.load_params(model_file, ctx=ctx)   # restore the best parameters\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data, label in test_loader:\n",
    "        data, label = data.as_in_context(ctx), label.as_in_context(ctx)\n",
    "        with autograd.record(train_mode=False):  # set the training_mode to False\n",
    "            output = model(data)\n",
    "        pred = nd.argmax(output, axis=1).asnumpy().tolist()\n",
    "        y_pred.extend(pred)\n",
    "        y_true.extend(label.asnumpy().tolist())\n",
    "\n",
    "    test_acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    test_f1 = metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    print(\"Test accuracy: {0:>7.2%}, F1-Score: {1:>7.2%}\".format(test_acc, test_f1))\n",
    "\n",
    "    print(\"Precision, Recall and F1-Score...\")\n",
    "    print(metrics.classification_report(y_true, y_pred, target_names=['NEG', 'POS']))\n",
    "\n",
    "    print('Confusion Matrix...')\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print(\"Time usage:\", get_time_dif(start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Configuring CNN model...\n",
      "('Initializing weights on', cpu(0))\n",
      "TextCNN(\n",
      "  (fc1): Dense(None -> 2, linear)\n",
      "  (dropout): Dropout(p = 0.6, axes=())\n",
      "  (conv3): Conv_Max_Pooling(\n",
      "    (conv): Conv1D(None -> 100, kernel_size=(4,), stride=(1,))\n",
      "    (pooling): GlobalMaxPool1D(size=(1,), stride=(1,), padding=(0,), ceil_mode=True)\n",
      "  )\n",
      "  (conv2): Conv_Max_Pooling(\n",
      "    (conv): Conv1D(None -> 100, kernel_size=(3,), stride=(1,))\n",
      "    (pooling): GlobalMaxPool1D(size=(1,), stride=(1,), padding=(0,), ceil_mode=True)\n",
      "  )\n",
      "  (conv1): Conv_Max_Pooling(\n",
      "    (conv): Conv1D(None -> 100, kernel_size=(2,), stride=(1,))\n",
      "    (pooling): GlobalMaxPool1D(size=(1,), stride=(1,), padding=(0,), ceil_mode=True)\n",
      "  )\n",
      "  (embedding): Embedding(7727 -> 300, float32)\n",
      ")\n",
      "Training and evaluating...\n",
      "Epoch   1, Train_loss:    0.35, Train_acc 85.71%, Test_loss:   0.33, Test_acc 88.08%, Time: 0:00:41 *\n",
      "Epoch   2, Train_loss:    0.32, Train_acc 85.71%, Test_loss:   0.32, Test_acc 88.08%, Time: 0:01:22 \n",
      "Epoch   3, Train_loss:     0.3, Train_acc 85.71%, Test_loss:    0.3, Test_acc 88.08%, Time: 0:02:01 \n",
      "Epoch   4, Train_loss:    0.29, Train_acc 86.21%, Test_loss:    0.3, Test_acc 88.74%, Time: 0:02:43 *\n",
      "Epoch   5, Train_loss:    0.28, Train_acc 86.46%, Test_loss:   0.29, Test_acc 88.74%, Time: 0:03:27 \n",
      "Epoch   6, Train_loss:    0.26, Train_acc 86.96%, Test_loss:   0.28, Test_acc 88.74%, Time: 0:04:08 \n",
      "Epoch   7, Train_loss:    0.25, Train_acc 87.54%, Test_loss:   0.28, Test_acc 88.74%, Time: 0:04:49 \n",
      "Epoch   8, Train_loss:    0.25, Train_acc 87.46%, Test_loss:   0.27, Test_acc 88.74%, Time: 0:05:30 \n",
      "Epoch   9, Train_loss:    0.24, Train_acc 88.12%, Test_loss:   0.27, Test_acc 89.07%, Time: 0:06:10 *\n",
      "Epoch  10, Train_loss:    0.23, Train_acc 88.37%, Test_loss:   0.26, Test_acc 89.40%, Time: 0:06:52 *\n",
      "Testing...\n",
      "Test accuracy:  89.40%, F1-Score:  57.16%\n",
      "Precision, Recall and F1-Score...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.89      1.00      0.94       266\n",
      "         POS       1.00      0.11      0.20        36\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       302\n",
      "   macro avg       0.95      0.56      0.57       302\n",
      "weighted avg       0.91      0.89      0.85       302\n",
      "\n",
      "Confusion Matrix...\n",
      "[[266   0]\n",
      " [ 32   4]]\n",
      "('Time usage:', datetime.timedelta(0, 3))\n"
     ]
    }
   ],
   "source": [
    "loss=[]\n",
    "train(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOn using fastText we see that the test accuracy on average has gone upto 94% as compared to around 90%\\nwhen using a normal embedding layer. This shows us that is important to incorporate the sub-word information\\noffered by fastText when training the CNN layer for better accuracy. This helps in dealing with previously\\nunseen words which can be in the form of spelling errors in tweets by associating them with words\\nalready encountered.\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use of fastText\n",
    "'''\n",
    "On using fastText we see that the test accuracy on average has gone upto 94% as compared to around 90%\n",
    "when using a normal embedding layer. This shows us that is important to incorporate the sub-word information\n",
    "offered by fastText when training the CNN layer for better accuracy. This helps in dealing with previously\n",
    "unseen words which can be in the form of spelling errors in tweets by associating them with words\n",
    "already encountered.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSince this is a skewed dataset accuracy is not a good measure of the performance as it gives equal weightage\\nto negative and positive classification. For this purpose we decide to use other measures like precision, recall,\\nF1-score. \\nThe relatively lower recall of the positive examples shows that our classifier is biased towards\\nclassifying negative examples. This is expected given the smaller percentage of positive examples as seen\\nfrom the support. \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measures of Accuracy\n",
    "'''\n",
    "Since this is a skewed dataset accuracy is not a good measure of the performance as it gives equal weightage\n",
    "to negative and positive classification. For this purpose we decide to use other measures like precision, recall,\n",
    "F1-score. \n",
    "The relatively lower recall of the positive examples shows that our classifier is biased towards\n",
    "classifying negative examples. This is expected given the smaller percentage of positive examples as seen\n",
    "from the support. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "'''\n",
    "We see that given the higher train accuracy and relatively lower test accuracy that the model is overfitting\n",
    "the data. Therefore we introduce Dropout and experiment with the Dropout rate to get an idea of how the model\n",
    "performs. We plot a graph of the F1-score of positive examples vs Dropout score\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22134680912344162, 0.1210429784764483, 0.06400577929427853, 0.03570195148231777, 0.021537292965276296, 0.0139366957263099, 0.011073357738133682, 0.01494792425785325, 0.010399755528676276, 0.006911406922386186]\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "'''\n",
    "From the graph of Dropout we observe that a value of ~0.5 is a good value for the Dropout rate.\n",
    "\n",
    "Another hyperparameter which we can experiment with is the sgd optimizer. We experiment with different\n",
    "optimizers like rmsprop, adam, adadelta, adagrad and nag by plotting the loss vs the number of epochs\n",
    "and compare them.\n",
    "'''\n",
    "adam=loss\n",
    "print (adam)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22897164075576587, 0.2055489333761095, 0.0860031706890543, 0.0470270368075648, 0.03189219031451994, 0.018120765832231142, 0.009695336783066565, 0.007388953394117298, 0.0065601830629081126, 0.005271682758626847]\n"
     ]
    }
   ],
   "source": [
    "rmsprop=loss\n",
    "print(rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21960905874364597, 0.12775591078935272, 0.07387387119171726, 0.04498517225214908, 0.02683140088083142, 0.016043398585758387, 0.009027463817145935, 0.04446468594800765, 0.01558469291730672, 0.010869572544006315]\n"
     ]
    }
   ],
   "source": [
    "adadelta=loss\n",
    "print (adadelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3508525948191798, 0.3223314627361456, 0.3031971598186366, 0.287048080632853, 0.2759555968582828, 0.26333734410446746, 0.2523258566064296, 0.2450596965181075, 0.23528286834491843, 0.22836931802307647]\n"
     ]
    }
   ],
   "source": [
    "adagrad=loss\n",
    "print (adagrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(adam,'r',label='adam') #in red\n",
    "plt.plot(rmsprop,'y',label='rmsprop') #in yellow\n",
    "plt.plot(adadelta,'b',label='adadelta') #in blue\n",
    "plt.plot(adagrad,'g',label='adagrad') #in green\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given the consistently lower training loss of adam and rmsprop, these would be a good optimizers for our task\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
